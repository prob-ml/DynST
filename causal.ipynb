{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae6c602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import Mimic3Dataset, padded_collate\n",
    "from src.model import DST\n",
    "import pdb\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from lifelines import CoxPHFitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53e0fa3",
   "metadata": {},
   "source": [
    "#### About\n",
    "\n",
    "Comparison of methods for computing ATE on restricted mean survival time. We used the following benchmarks:\n",
    "- Outcome Regression with DynST\n",
    "- Outcome Regression with Cox Model\n",
    "- Logistic IPW\n",
    "- AIPW (logistic propensity score model and DynST outcome model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ad6665",
   "metadata": {},
   "source": [
    "#### True ATE\n",
    "- $\\tau = 8$: 0.265\n",
    "- $\\tau = 12$: 0.572\n",
    "- $\\tau = 16$: 0.946"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513cbcec",
   "metadata": {},
   "source": [
    "#### Unadjusted Treatment Effect\n",
    "- $\\tau = 8$: -0.237\n",
    "- $\\tau = 12$: -0.539\n",
    "- $\\tau = 16$: -0.933"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4e3b4e",
   "metadata": {},
   "source": [
    "### Outcome Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d1ed5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_treated = Mimic3Dataset(\".\", intervention=True, seed=30)\n",
    "dataset_control = Mimic3Dataset(\".\", intervention=False, seed=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61cf1ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = [\"multirun/2022-09-19/13-54-24/70/11/lightning_logs/version_0/checkpoints/epoch=3-step=3036.ckpt\",\n",
    "              \"multirun/2022-09-19/13-54-24/71/15/lightning_logs/version_0/checkpoints/epoch=3-step=3036.ckpt\",\n",
    "              \"multirun/2022-09-19/13-54-24/72/35/lightning_logs/version_0/checkpoints/epoch=3-step=3036.ckpt\",\n",
    "              \"multirun/2022-09-19/13-54-37/73/1/lightning_logs/version_0/checkpoints/epoch=3-step=3036.ckpt\",\n",
    "              \"multirun/2022-09-19/13-54-37/74/17/lightning_logs/version_0/checkpoints/epoch=2-step=2277.ckpt\",\n",
    "              \"multirun/2022-09-19/13-54-37/75/25/lightning_logs/version_0/checkpoints/epoch=3-step=3036.ckpt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "743c25b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = lambda x: padded_collate(x, pad_index=-100, causal=True)\n",
    "def get_predictions(model, dataset):\n",
    "    dl = torch.utils.data.DataLoader(dataset, collate_fn=collate_fn, batch_size=96)\n",
    "    predictor = pl.Trainer(gpus=[5])\n",
    "    predictions = predictor.predict(model, dataloaders=dl)\n",
    "    return torch.cat(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faeb4e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pchatha/.cache/pypoetry/virtualenvs/mimic-slGwTqhJ-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=[5])` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=[5])` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/pchatha/.cache/pypoetry/virtualenvs/mimic-slGwTqhJ-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a355a364764b41dcb6ede76bc651170d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pchatha/DynST/src/dataset.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item[\"codes\"] = torch.tensor(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ffb18b2f7a42c0b160609ed8c23664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26e173537c946a59d7ff4f7d9d61949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298f54182dab4c97b5a2f1caf8cbccc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7895306acac04705b1fb5bba61d0ed37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c26fe3d2d5541e09276a0ffbe567c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4981ceccc8094b6a98871ef3d33886dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f08a51b1f469475485ac92377e350bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed5b3c9aedf4648b5ae5981c0dd9ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b7bf8bacbd4467baca0309cf6c84d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43383f5be29c4f5e8bbe11ffea818a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4c505403274390b87bac954cac2430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_treated = []\n",
    "predict_control = []\n",
    "seeds = [70,71,72,73,74,75]\n",
    "for ix, c in enumerate(checkpoints):\n",
    "    print(seeds[ix])\n",
    "    model = DST.load_from_checkpoint(c)\n",
    "    predict_treated.append(get_predictions(model, dataset_treated))\n",
    "    predict_control.append(get_predictions(model, dataset_control))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bc4f33",
   "metadata": {},
   "source": [
    "#### Outcome Regression Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e00a3a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(0.1700)\n",
      "tensor(0.4110)\n",
      "tensor(0.6255)\n",
      "1\n",
      "tensor(0.0733)\n",
      "tensor(0.3657)\n",
      "tensor(0.7719)\n",
      "2\n",
      "tensor(0.1028)\n",
      "tensor(0.3217)\n",
      "tensor(0.6130)\n",
      "3\n",
      "tensor(0.0900)\n",
      "tensor(0.3784)\n",
      "tensor(0.7639)\n",
      "4\n",
      "tensor(0.1680)\n",
      "tensor(0.5457)\n",
      "tensor(0.8904)\n",
      "5\n",
      "tensor(0.1077)\n",
      "tensor(0.4523)\n",
      "tensor(0.8688)\n"
     ]
    }
   ],
   "source": [
    "taus = [8, 12, 16]\n",
    "for i in range(len(predict_treated)):\n",
    "    print(i)\n",
    "    for tau in taus:    \n",
    "        cutoff = torch.full(predict_treated[0].shape, tau)\n",
    "        ey_x1 = torch.minimum(cutoff, predict_treated[i])\n",
    "        ey_x0 = torch.minimum(cutoff, predict_control[i])\n",
    "        print(ey_x1.mean() - ey_x0.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67581ed1",
   "metadata": {},
   "source": [
    "### Cox Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6eb6484",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/mimic3_df_30.csv\", index_col=[0,1])\n",
    "df_sub = df.drop(\n",
    "    columns=[\"treated\", \"control\", \"hazard\", \"q\", \"survival_prob\", \n",
    "             \"survives\", \"censored\",\"corrected_survival\", \"critical\", \"first_failure\",\n",
    "            \"baseline_hazard\"]\n",
    ")\n",
    "df_flat = df_sub.groupby(level=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b12dba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flat[\"total_hours\"] = df.groupby(level=0)[\"corrected_survival\"].sum()\n",
    "df_flat[\"uncensored\"] = (df.groupby(level=0)[\"corrected_survival\"].min() == 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0edd24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = df_flat.copy()\n",
    "df_t[\"A\"] = 1\n",
    "df_c = df_flat.copy()\n",
    "df_c[\"A\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c66e24",
   "metadata": {},
   "source": [
    "### Cross validating..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e381c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(df, y_hat):\n",
    "    a = np.abs((df[\"total_hours\"] - y_hat)[df[\"uncensored\"].astype(bool)]).sum()\n",
    "    b = np.maximum(np.zeros(df.shape[0]), df[\"total_hours\"] - y_hat).sum()\n",
    "    return (a + b) / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1a104b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_treated = []\n",
    "predict_control = []\n",
    "for seed in [71, 72, 73, 74, 75, 76, 77]:\n",
    "    train, val = train_test_split(df_flat, train_size=0.8, random_state=seed)\n",
    "    val_scores = []\n",
    "    models = []\n",
    "    for lam in [0, .1, .2,]:\n",
    "        cph = CoxPHFitter(penalizer=lam)\n",
    "        cph.fit(train, duration_col=\"total_hours\", event_col=\"uncensored\")\n",
    "        models.append(cph)\n",
    "        y_hat_val = cph.predict_expectation(val)\n",
    "        val_scores.append(mae(val, y_hat_val))\n",
    "    best_ix = np.argmin(val_scores)\n",
    "    best_model = models[best_ix]\n",
    "    predict_treated.append(best_model.predict_expectation(df_t))\n",
    "    predict_control.append((best_model.predict_expectation(df_c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7509b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.006990906215971648\n",
      "0.04817908881326538\n",
      "0.20784206957636364\n",
      "1\n",
      "0.005685950504813242\n",
      "0.04674804763620877\n",
      "0.1989215854282982\n",
      "2\n",
      "0.005243515192804082\n",
      "0.04662786868173363\n",
      "0.19497070653980053\n",
      "3\n",
      "0.0054282330270361\n",
      "0.046855169459851354\n",
      "0.1981455591943888\n",
      "4\n",
      "0.005037709638730625\n",
      "0.0447034001044706\n",
      "0.18694627135277742\n",
      "5\n",
      "0.0049232193938832935\n",
      "0.04578574127161161\n",
      "0.19545287258091193\n",
      "6\n",
      "0.003975559105430904\n",
      "0.045807192170666866\n",
      "0.18713421894600657\n"
     ]
    }
   ],
   "source": [
    "taus = [8, 12, 16]\n",
    "for i in range(len(predict_treated)):\n",
    "    print(i)\n",
    "    for tau in taus:        \n",
    "        cutoff = np.full(len(df_flat), tau)\n",
    "        ey_x1 = np.minimum(cutoff, predict_treated[i])\n",
    "        ey_x0 = np.minimum(cutoff, predict_control[i])\n",
    "        print(ey_x1.mean() - ey_x0.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c6d27a",
   "metadata": {},
   "source": [
    "### Propensity Score Weighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d76d62f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>stay_length</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>coronary_ath</th>\n",
       "      <th>atrial_fib</th>\n",
       "      <th>hematocrit</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>platelets</th>\n",
       "      <th>mean blood pressure</th>\n",
       "      <th>treated</th>\n",
       "      <th>...</th>\n",
       "      <th>A</th>\n",
       "      <th>baseline_hazard</th>\n",
       "      <th>hazard</th>\n",
       "      <th>critical</th>\n",
       "      <th>q</th>\n",
       "      <th>survival_prob</th>\n",
       "      <th>survives</th>\n",
       "      <th>first_failure</th>\n",
       "      <th>censored</th>\n",
       "      <th>corrected_survival</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th>hours_in</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">4</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.360949</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076528</td>\n",
       "      <td>-0.111641</td>\n",
       "      <td>-0.187116</td>\n",
       "      <td>2.523323</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998987</td>\n",
       "      <td>0.998097</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.360949</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076528</td>\n",
       "      <td>-0.111641</td>\n",
       "      <td>-0.187116</td>\n",
       "      <td>0.082396</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999211</td>\n",
       "      <td>0.999160</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.360949</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076528</td>\n",
       "      <td>-0.111641</td>\n",
       "      <td>-0.187116</td>\n",
       "      <td>0.082396</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999386</td>\n",
       "      <td>0.996084</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.360949</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076528</td>\n",
       "      <td>-0.111641</td>\n",
       "      <td>-0.187116</td>\n",
       "      <td>-0.490692</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999504</td>\n",
       "      <td>0.997700</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.360949</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076528</td>\n",
       "      <td>-0.111641</td>\n",
       "      <td>-0.187116</td>\n",
       "      <td>-0.320892</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999622</td>\n",
       "      <td>0.996546</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     gender  stay_length  hypertension  coronary_ath  \\\n",
       "subject_id hours_in                                                    \n",
       "4          0              0    -0.360949             0             0   \n",
       "           1              0    -0.360949             0             0   \n",
       "           2              0    -0.360949             0             0   \n",
       "           3              0    -0.360949             0             0   \n",
       "           4              0    -0.360949             0             0   \n",
       "\n",
       "                     atrial_fib  hematocrit  hemoglobin  platelets  \\\n",
       "subject_id hours_in                                                  \n",
       "4          0                  0    0.076528   -0.111641  -0.187116   \n",
       "           1                  0    0.076528   -0.111641  -0.187116   \n",
       "           2                  0    0.076528   -0.111641  -0.187116   \n",
       "           3                  0    0.076528   -0.111641  -0.187116   \n",
       "           4                  0    0.076528   -0.111641  -0.187116   \n",
       "\n",
       "                     mean blood pressure  treated  ...    A  baseline_hazard  \\\n",
       "subject_id hours_in                                ...                         \n",
       "4          0                    2.523323        1  ...  0.0         0.001000   \n",
       "           1                    0.082396        1  ...  0.0         0.000779   \n",
       "           2                    0.082396        1  ...  0.0         0.000607   \n",
       "           3                   -0.490692        1  ...  0.0         0.000472   \n",
       "           4                   -0.320892        1  ...  0.0         0.000368   \n",
       "\n",
       "                       hazard  critical         q  survival_prob  survives  \\\n",
       "subject_id hours_in                                                          \n",
       "4          0         0.001013         0  0.998987       0.998097         1   \n",
       "           1         0.000789         0  0.999211       0.999160         1   \n",
       "           2         0.000614         0  0.999386       0.996084         1   \n",
       "           3         0.000496         0  0.999504       0.997700         1   \n",
       "           4         0.000378         0  0.999622       0.996546         1   \n",
       "\n",
       "                     first_failure censored  corrected_survival  \n",
       "subject_id hours_in                                              \n",
       "4          0                   NaN     True                   1  \n",
       "           1                   NaN     True                   1  \n",
       "           2                   NaN     True                   1  \n",
       "           3                   NaN     True                   1  \n",
       "           4                   NaN     True                   1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/mimic3_df_30.csv\", index_col=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbfe649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"A\",\"hypertension\", \"coronary_ath\", \"atrial_fib\" ]\n",
    "df_flat = df[cols].groupby(level=0).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dcbaaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "propensities = []\n",
    "for seed in [71, 72, 73, 74, 75, 76, 77]:\n",
    "    lr = LogisticRegressionCV(random_state=seed, max_iter=100)\n",
    "    lr.fit(df_flat.drop(columns=\"A\"), df_flat[\"A\"])\n",
    "    lr.score(df_flat.drop(columns=\"A\"), df_flat[\"A\"])\n",
    "    pi_x = lr.predict_proba(df_flat.drop(columns=\"A\"))[:, 1]\n",
    "    propensities.append(pi_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82d21ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ipw(y, t, pi_x):\n",
    "    p1 = (y * t) / pi_x\n",
    "    p2 = ((1 - t) * y) / (1 - pi_x)\n",
    "    return (p1 - p2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a69a95d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5218639886321306\n",
      "0.9275064793300295\n",
      "1.3620698921976284\n",
      "***\n",
      "0.5218639886321306\n",
      "0.9275064793300295\n",
      "1.3620698921976284\n",
      "***\n",
      "0.5218639886321306\n",
      "0.9275064793300295\n",
      "1.3620698921976284\n",
      "***\n",
      "0.5218639886321306\n",
      "0.9275064793300295\n",
      "1.3620698921976284\n",
      "***\n",
      "0.5218639886321306\n",
      "0.9275064793300295\n",
      "1.3620698921976284\n",
      "***\n",
      "0.5218639886321306\n",
      "0.9275064793300295\n",
      "1.3620698921976284\n",
      "***\n",
      "0.5218639886321306\n",
      "0.9275064793300295\n",
      "1.3620698921976284\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "t = df.groupby(level=0)[\"A\"].any().astype(int)\n",
    "for pi_x in propensities:\n",
    "    for tau in [8,12,16]:\n",
    "        surv_restr = df.groupby(level=0)[\"corrected_survival\"].head(tau)\n",
    "        y = surv_restr.groupby(level=0).sum()\n",
    "        print(ipw(y, t, pi_x))\n",
    "    print(\"***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d75584",
   "metadata": {},
   "source": [
    "### AIPW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28980bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aipw(y, t, pi_x, ey_x1, ey_x0):\n",
    "    b1 = ((t * y) / pi_x) - (((1 - t) * y) / (1 - pi_x))\n",
    "    b2 = (t - pi_x) / (pi_x * (1 - pi_x)) * ((1 - pi_x) * ey_x1.numpy() + pi_x * ey_x0.numpy())\n",
    "    return b1.mean() - b2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48fc5110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.2449780630071885\n",
      "0.6446655469578944\n",
      "1.1689455879817172\n",
      "1\n",
      "0.20984590972150602\n",
      "0.5189298083180993\n",
      "0.9954442420118628\n",
      "2\n",
      "0.22329082169686076\n",
      "0.5758678432394009\n",
      "1.0657333240910896\n",
      "3\n",
      "0.21811878943630775\n",
      "0.53925737975217\n",
      "1.011066912574107\n",
      "4\n",
      "0.23717831059358457\n",
      "0.6600351872592145\n",
      "1.196138547877693\n",
      "5\n",
      "0.2226971317555551\n",
      "0.5723569840637329\n",
      "1.0625096558344098\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(predict_treated)):\n",
    "    print(i)\n",
    "    for tau in [8,12,16]:\n",
    "        surv_restr = df.groupby(level=0)[\"corrected_survival\"].head(tau)\n",
    "        y = surv_restr.groupby(level=0).sum()\n",
    "        cutoff = torch.full(predict_treated[0].shape, tau)\n",
    "        ey_x1 = torch.minimum(cutoff, predict_treated[i])\n",
    "        ey_x0 = torch.minimum(cutoff, predict_control[i])\n",
    "        print(aipw(y, t, pi_x, ey_x1, ey_x0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
